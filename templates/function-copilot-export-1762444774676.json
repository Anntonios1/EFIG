[{"id":"copilot","user_id":"3ac901b2-930b-45cc-947a-0d27c8420b4e","name":"Copilot","type":"pipe","content":"\"\"\"\ntitle: GitHub Copilot Enhanced v2.0 - Optimized\nauthor: AI Assistant with improvements\nversion: 2.0.0\nrequired_open_webui_version: 0.4.0\nlicense: MIT\ndescription: Optimized GitHub Copilot integration with improved performance, cleaner event handling, and better error management\nrequirements: pydantic\n\"\"\"\n\nimport os\nimport time\nimport json\nimport uuid\nimport urllib.request\nimport urllib.error\nimport re\nimport random\nimport logging\nimport hashlib\nfrom pathlib import Path\nfrom pydantic import BaseModel, Field\nfrom typing import Iterator, List, Optional, Dict, Any, Union\nfrom concurrent.futures import ThreadPoolExecutor\nfrom functools import lru_cache\n\n# Configure structured logging\nlogging.basicConfig(\n    level=logging.INFO, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n)\nlogger = logging.getLogger(__name__)\n\n\nclass TokenCache:\n    \"\"\"Enhanced persistent token cache with thread safety\"\"\"\n\n    def __init__(self, cache_dir: Optional[str] = None):\n        self.cache_dir = Path(cache_dir or os.path.expanduser(\"~/.copilot_cache\"))\n        self.cache_dir.mkdir(parents=True, exist_ok=True)\n        self.cache_file = self.cache_dir / \"token_cache.json\"\n\n    def get_token(self, api_key_hash: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Retrieve cached token if valid with improved error handling\"\"\"\n        try:\n            if not self.cache_file.exists():\n                return None\n\n            with open(self.cache_file, \"r\", encoding=\"utf-8\") as f:\n                cache_data = json.load(f)\n\n            if cache_data.get(\"api_key_hash\") != api_key_hash:\n                return None\n\n            token_data = cache_data.get(\"token_data\", {})\n            expires_at = token_data.get(\"expires_at\", 0)\n\n            # Check if token is still valid (with 120s buffer for better safety)\n            if time.time() < expires_at - 120:\n                logger.debug(\"Using cached token\")\n                return token_data\n\n        except (json.JSONDecodeError, KeyError, OSError) as e:\n            logger.warning(f\"Token cache read error: {e}\")\n            self._clean_corrupted_cache()\n\n        return None\n\n    def save_token(self, api_key_hash: str, token_data: Dict[str, Any]):\n        \"\"\"Save token to cache with atomic write\"\"\"\n        try:\n            cache_data = {\n                \"api_key_hash\": api_key_hash,\n                \"token_data\": token_data,\n                \"cached_at\": time.time(),\n            }\n\n            # Atomic write using temp file\n            temp_file = self.cache_file.with_suffix(\".tmp\")\n            with open(temp_file, \"w\", encoding=\"utf-8\") as f:\n                json.dump(cache_data, f, indent=2)\n\n            temp_file.replace(self.cache_file)\n            logger.debug(\"Token cached successfully\")\n\n        except OSError as e:\n            logger.warning(f\"Failed to save token cache: {e}\")\n\n    def clear_cache(self):\n        \"\"\"Clear token cache safely\"\"\"\n        try:\n            if self.cache_file.exists():\n                self.cache_file.unlink()\n                logger.info(\"Token cache cleared\")\n        except OSError as e:\n            logger.warning(f\"Failed to clear token cache: {e}\")\n\n    def _clean_corrupted_cache(self):\n        \"\"\"Clean corrupted cache file\"\"\"\n        try:\n            if self.cache_file.exists():\n                self.cache_file.unlink()\n                logger.info(\"Corrupted cache file removed\")\n        except OSError:\n            pass\n\n\nclass WolframResultFormatter:\n    \"\"\"Optimized Wolfram results formatter with better parsing\"\"\"\n\n    @staticmethod\n    @lru_cache(maxsize=128)\n    def _compile_patterns():\n        \"\"\"Compile regex patterns once for better performance\"\"\"\n        return {\n            \"images\": re.compile(\n                r\"https://[^\\s]+\\.(?:png|jpg|jpeg|gif)\", re.IGNORECASE\n            ),\n            \"derivative\": re.compile(r\"d/dx\\([^)]+\\)\\s*=\\s*([^\\n]+)\", re.IGNORECASE),\n            \"integral\": re.compile(r\"integral[^=]+=\\s*([^\\n]+)\", re.IGNORECASE),\n            \"roots\": re.compile(r\"x\\s*‚âà\\s*([^\\n]+)\"),\n            \"series\": re.compile(r\"Series expansion[^:]*:\\s*([^\\n]+)\", re.IGNORECASE),\n            \"domain\": re.compile(r\"Domain:\\s*([^\\n]+)\", re.IGNORECASE),\n            \"range\": re.compile(r\"Range:\\s*([^\\n]+)\", re.IGNORECASE),\n            \"alternate\": re.compile(r\"Alternate form:\\s*([^\\n]+)\", re.IGNORECASE),\n        }\n\n    @classmethod\n    def parse_wolfram_response(cls, wolfram_json: str) -> Dict[str, Any]:\n        \"\"\"Parse Wolfram JSON response with better error handling\"\"\"\n        try:\n            return json.loads(wolfram_json) if wolfram_json else {}\n        except (json.JSONDecodeError, TypeError) as e:\n            logger.error(f\"Failed to parse Wolfram response: {e}\")\n            return {}\n\n    @classmethod\n    def extract_images(cls, response_text: str) -> List[str]:\n        \"\"\"Extract and validate image URLs efficiently\"\"\"\n        if not response_text:\n            return []\n\n        patterns = cls._compile_patterns()\n        urls = patterns[\"images\"].findall(response_text)\n\n        # Clean and validate URLs\n        valid_urls = []\n        for url in urls[:8]:  # Increased limit but still reasonable\n            url = re.sub(r\"[.,;!?]+$\", \"\", url)\n            if url.startswith(\"http\") and len(url) < 500:  # Sanity check\n                valid_urls.append(url)\n\n        return valid_urls\n\n    @classmethod\n    def extract_key_results(cls, response_text: str, query_type: str) -> Dict[str, Any]:\n        \"\"\"Extract mathematical results with compiled patterns\"\"\"\n        if not response_text:\n            return {}\n\n        results = {}\n        patterns = cls._compile_patterns()\n\n        # Extract main result based on type\n        if query_type == \"derivative\" and patterns[\"derivative\"]:\n            match = patterns[\"derivative\"].search(response_text)\n            if match:\n                results[\"main_result\"] = match.group(1).strip()\n        elif query_type == \"integral\" and patterns[\"integral\"]:\n            match = patterns[\"integral\"].search(response_text)\n            if match:\n                results[\"main_result\"] = match.group(1).strip()\n\n        # Extract other components\n        components = [\"roots\", \"series\", \"domain\", \"range\", \"alternate\"]\n        for component in components:\n            if patterns[component]:\n                match = patterns[component].search(response_text)\n                if match:\n                    if component == \"roots\":\n                        # Find all roots, not just first\n                        roots = patterns[component].findall(response_text)\n                        results[component] = roots[:6]  # Limit to 6 roots\n                    else:\n                        results[component] = match.group(1).strip()\n\n        return results\n\n    @classmethod\n    def format_verification_block(cls, data: Dict[str, Any]) -> str:\n        \"\"\"Create optimized verification block\"\"\"\n        if not data.get(\"success\"):\n            return \"\\n\\n---\\n\\n### ‚ö†Ô∏è Verificaci√≥n no disponible\\n\\n\"\n\n        response_text = data.get(\"response\", \"\")\n        query_type = data.get(\"query\", {}).get(\"type\", \"general\")\n\n        # Extract components efficiently\n        images = cls.extract_images(response_text)\n        key_results = cls.extract_key_results(response_text, query_type)\n\n        # Build formatted output\n        output = [\"\\n\\n---\\n\\n## üî¨ Verificaci√≥n con WolframAlpha\\n\\n\"]\n\n        # Main result\n        if key_results.get(\"main_result\"):\n            output.extend(\n                [\"### ‚úÖ Resultado\\n\\n\", f\"$$\\n{key_results['main_result']}\\n$$\\n\\n\"]\n            )\n\n        # Visualizations (limit to 3 for performance)\n        if images:\n            output.append(\"### üìä Visualizaciones\\n\\n\")\n            for i, img_url in enumerate(images[:3], 1):\n                output.append(f\"![Gr√°fica {i}]({img_url})\\n\\n\")\n\n        # Properties\n        properties = []\n        if key_results.get(\"domain\"):\n            properties.append(f\"- **Dominio:** {key_results['domain']}\")\n        if key_results.get(\"range\"):\n            properties.append(f\"- **Rango:** {key_results['range']}\")\n\n        if properties:\n            output.append(\"### üìê Propiedades\\n\\n\")\n            output.extend(properties)\n            output.append(\"\\n\\n\")\n\n        # Series and roots (if present)\n        if key_results.get(\"series\"):\n            output.extend(\n                [\n                    \"### üî¢ Expansi√≥n en serie\\n\\n\",\n                    f\"$$\\n{key_results['series']}\\n$$\\n\\n\",\n                ]\n            )\n\n        if key_results.get(\"roots\"):\n            output.append(\"### üìç Ra√≠ces num√©ricas\\n\\n\")\n            for root in key_results[\"roots\"][:4]:\n                output.append(f\"- $x ‚âà {root.strip()}$\\n\")\n            output.append(\"\\n\")\n\n        # Alternate form\n        if key_results.get(\"alternate\"):\n            output.extend(\n                [\n                    \"### üîÑ Forma alternativa\\n\\n\",\n                    f\"$$\\n{key_results['alternate']}\\n$$\\n\\n\",\n                ]\n            )\n\n        # Link to full results\n        webapp_url = data.get(\"urls\", {}).get(\"webapp\")\n        if webapp_url:\n            output.append(f\"[üìñ Ver an√°lisis completo]({webapp_url})\\n\\n\")\n\n        return \"\".join(output)\n\n\nclass MathDetector:\n    \"\"\"Optimized math query detector with compiled patterns\"\"\"\n\n    # Compile patterns once at class level\n    _COMPILED_PATTERNS = {\n        \"derivative\": re.compile(\n            r\"\\b(?:derivada?s?|derivative|d/dx|diferencial|differentiate|‚àÇ|‚àá)\\b\",\n            re.IGNORECASE,\n        ),\n        \"integral\": re.compile(\n            r\"\\b(?:integral?e?s?|integrate|‚à´|integrar|antiderivada)\\b\", re.IGNORECASE\n        ),\n        \"equation\": re.compile(\n            r\"\\b(?:ecuaci[o√≥]n|equation|resolver?|solve|ra[√≠i]ces|roots)\\b\",\n            re.IGNORECASE,\n        ),\n        \"limit\": re.compile(\n            r\"\\b(?:l[√≠i]mite?s?|limit|tiende|approaches?|lim)\\b\", re.IGNORECASE\n        ),\n        \"matrix\": re.compile(\n            r\"\\b(?:matriz|matrix|determinante?|determinant|eigenvalue|eigenvector)\\b\",\n            re.IGNORECASE,\n        ),\n        \"calculation\": re.compile(\n            r\"\\b(?:calcular?|calculate|computar?|compute|evaluar?|evaluate)\\b\",\n            re.IGNORECASE,\n        ),\n        \"trigonometry\": re.compile(\n            r\"\\b(?:sin|cos|tan|sec|csc|cot|arcsin|arccos|arctan|sinh|cosh|tanh)\\b\",\n            re.IGNORECASE,\n        ),\n        \"scientific\": re.compile(r\"\\d+\\.?\\d*[eE][+-]?\\d+\"),\n    }\n\n    # Extended math symbols for faster lookup\n    _MATH_SYMBOLS = frozenset(\n        [\n            \"=\",\n            \"+\",\n            \"-\",\n            \"√ó\",\n            \"√∑\",\n            \"^\",\n            \"‚à´\",\n            \"‚àÇ\",\n            \"‚àÜ\",\n            \"Œ£\",\n            \"‚àö\",\n            \"œÄ\",\n            \"‚àá\",\n            \"‚äó\",\n            \"‚äï\",\n            \"‚äô\",\n            \"‚àà\",\n            \"‚àâ\",\n            \"‚äÇ\",\n            \"‚äÜ\",\n            \"‚à™\",\n            \"‚à©\",\n            \"‚âà\",\n            \"‚â†\",\n            \"‚â§\",\n            \"‚â•\",\n            \"‚àû\",\n            \"Œ±\",\n            \"Œ≤\",\n            \"Œ≥\",\n            \"Œ¥\",\n            \"Œ∏\",\n            \"Œª\",\n            \"Œº\",\n            \"œÉ\",\n            \"œÜ\",\n            \"œâ\",\n        ]\n    )\n\n    @classmethod\n    def is_math_query(cls, text: str) -> bool:\n        \"\"\"Optimized mathematical query detection\"\"\"\n        if not isinstance(text, str) or not text.strip():\n            return False\n\n        # Fast symbol check first\n        if any(symbol in text for symbol in cls._MATH_SYMBOLS):\n            return True\n\n        # Pattern matching\n        return any(pattern.search(text) for pattern in cls._COMPILED_PATTERNS.values())\n\n    @classmethod\n    def get_math_type(cls, text: str) -> Optional[str]:\n        \"\"\"Get type of math query efficiently\"\"\"\n        if not isinstance(text, str):\n            return None\n\n        for math_type, pattern in cls._COMPILED_PATTERNS.items():\n            if pattern.search(text):\n                return math_type\n        return None\n\n    @classmethod\n    @lru_cache(maxsize=64)\n    def _get_extraction_patterns(self):\n        \"\"\"Compile extraction patterns once\"\"\"\n        return [\n            re.compile(\n                r\"(?:deriva(?:da|r)|derivative)\\s+(?:de\\s+)?(.+?)(?:\\s+con\\s+respecto|\\s+wrt|$)\",\n                re.IGNORECASE,\n            ),\n            re.compile(\n                r\"(?:integr(?:al|ar)|integrate)\\s+(?:de\\s+)?(.+?)(?:\\s+d[a-z]|$)\",\n                re.IGNORECASE,\n            ),\n            re.compile(r\"(?:resolver?|solve)\\s+(.+?)(?:\\s+para|$)\", re.IGNORECASE),\n            re.compile(r\"(?:calcular?|calculate)\\s+(.+)$\", re.IGNORECASE),\n        ]\n\n    @classmethod\n    def extract_expression(cls, text: str) -> Optional[str]:\n        \"\"\"Extract mathematical expression efficiently\"\"\"\n        if not isinstance(text, str):\n            return None\n\n        patterns = cls._get_extraction_patterns()\n        for pattern in patterns:\n            match = pattern.search(text)\n            if match:\n                return match.group(1).strip()\n        return None\n\n\nclass LaTeXProcessor:\n    \"\"\"Optimized LaTeX processor with better performance\"\"\"\n\n    # Compile LaTeX indicators once\n    _LATEX_INDICATORS = frozenset(\n        [\n            \"$\",\n            \"\\\\frac\",\n            \"\\\\sum\",\n            \"\\\\int\",\n            \"\\\\prod\",\n            \"\\\\lim\",\n            \"\\\\sqrt\",\n            \"\\\\alpha\",\n            \"\\\\beta\",\n            \"\\\\gamma\",\n            \"\\\\theta\",\n            \"\\\\pi\",\n            \"\\\\lambda\",\n            \"\\\\begin{equation}\",\n            \"\\\\begin{align}\",\n            \"\\\\begin{cases}\",\n            \"\\\\begin{matrix}\",\n            \"\\\\begin{bmatrix}\",\n            \"\\\\text{\",\n            \"^{\",\n            \"_{\",\n            \"\\\\cdot\",\n        ]\n    )\n\n    @classmethod\n    def detect_math_content(cls, content: str) -> bool:\n        \"\"\"Fast math content detection\"\"\"\n        if not isinstance(content, str):\n            return False\n\n        return any(indicator in content for indicator in cls._LATEX_INDICATORS)\n\n    @classmethod\n    def enhance_math_prompt(\n        cls, messages: List[Dict], has_wolfram: bool = False\n    ) -> List[Dict]:\n        \"\"\"Enhanced math prompt optimization\"\"\"\n        enhanced_messages = []\n\n        # Check for math content efficiently\n        has_math = any(\n            cls.detect_math_content(str(msg.get(\"content\", \"\")))\n            for msg in messages[-3:]  # Only check last 3 messages for performance\n        )\n\n        if has_math:\n            instruction_content = (\n                \"MATH FORMATTING RULES:\\n\"\n                \"- Use $...$ for inline math (e.g., $x^2$)\\n\"\n                \"- Use $$...$$ for display equations (separate lines)\\n\"\n                \"- Proper LaTeX: \\\\frac{a}{b}, \\\\sum_{i=1}^{n}, \\\\int_{a}^{b}\\n\"\n                \"- Clean spacing and readability\\n\"\n            )\n\n            if has_wolfram:\n                instruction_content += (\n                    \"\\nWOLFRAM VERIFICATION:\\n\"\n                    \"- Present clear step-by-step solutions\\n\"\n                    \"- Verification will appear automatically\\n\"\n                )\n\n            enhanced_messages.append({\"role\": \"system\", \"content\": instruction_content})\n\n        enhanced_messages.extend(messages)\n        return enhanced_messages\n\n    @classmethod\n    def fix_latex_formatting(cls, content: str) -> str:\n        \"\"\"Optimized LaTeX formatting fixes\"\"\"\n        if not isinstance(content, str) or len(content) == 0:\n            return content\n\n        # Apply fixes efficiently\n        fixes = [\n            (re.compile(r\"([^\\n])\\$\\$\"), r\"\\1\\n$$\"),\n            (re.compile(r\"\\$\\$([^\\n])\"), r\"$$\\n\\1\"),\n            (re.compile(r\"\\\\frac\\s*\\{([^}]*)\\}\\s*\\{([^}]*)\\}\"), r\"\\\\frac{\\1}{\\2}\"),\n            (re.compile(r\"_\\s*\\{\"), r\"_{\"),\n            (re.compile(r\"\\^\\s*\\{\"), r\"^{\"),\n        ]\n\n        result = content\n        for pattern, replacement in fixes:\n            result = pattern.sub(replacement, result)\n\n        return result\n\n\nclass RetryHandler:\n    \"\"\"Optimized retry handler with better error classification\"\"\"\n\n    _RETRYABLE_ERRORS = frozenset(\n        [\n            \"timeout\",\n            \"connection\",\n            \"temporary\",\n            \"server error\",\n            \"502\",\n            \"503\",\n            \"504\",\n            \"429\",\n            \"rate limit\",\n        ]\n    )\n\n    @staticmethod\n    def with_retry(operation, max_retries=3, base_delay=1.0, max_delay=30.0):\n        \"\"\"Execute operation with optimized retry logic\"\"\"\n        last_error = None\n\n        for attempt in range(max_retries + 1):\n            try:\n                return operation()\n            except Exception as e:\n                last_error = e\n\n                if attempt == max_retries:\n                    break\n\n                if not RetryHandler._is_retryable_error(e):\n                    raise e\n\n                # Optimized delay calculation\n                delay = min(base_delay * (2**attempt), max_delay)\n                jitter = delay * 0.1 * (random.random() - 0.5)\n                final_delay = max(0.1, delay + jitter)\n\n                logger.debug(f\"Retry {attempt + 1} in {final_delay:.1f}s: {e}\")\n                time.sleep(final_delay)\n\n        raise last_error\n\n    @staticmethod\n    def _is_retryable_error(error) -> bool:\n        \"\"\"Fast error classification\"\"\"\n        error_str = str(error).lower()\n        return any(\n            indicator in error_str for indicator in RetryHandler._RETRYABLE_ERRORS\n        )\n\n\nclass RequestValidator:\n    \"\"\"Streamlined request validator\"\"\"\n\n    _NUMERIC_PARAMS = {\n        \"temperature\": (0.0, 2.0, 0.7),\n        \"top_p\": (0.0, 1.0, 1.0),\n        \"max_tokens\": (1, 32000, 4000),\n        \"presence_penalty\": (-2.0, 2.0, 0.0),\n        \"frequency_penalty\": (-2.0, 2.0, 0.0),\n    }\n\n    @staticmethod\n    def validate_and_sanitize(body: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Optimized validation and sanitization\"\"\"\n        sanitized = body.copy()\n\n        # Validate numeric parameters\n        for param, (\n            min_val,\n            max_val,\n            default,\n        ) in RequestValidator._NUMERIC_PARAMS.items():\n            if param in sanitized and sanitized[param] is not None:\n                try:\n                    val = float(sanitized[param])\n                    sanitized[param] = max(min_val, min(val, max_val))\n                    if param == \"max_tokens\":\n                        sanitized[param] = int(sanitized[param])\n                except (ValueError, TypeError):\n                    sanitized[param] = default\n                    logger.debug(f\"Invalid {param}, using default: {default}\")\n\n        # Sanitize messages\n        if \"messages\" in sanitized:\n            sanitized[\"messages\"] = RequestValidator._sanitize_messages(\n                sanitized[\"messages\"]\n            )\n\n        return sanitized\n\n    @staticmethod\n    def _sanitize_messages(messages: List[Dict]) -> List[Dict]:\n        \"\"\"Efficient message sanitization\"\"\"\n        if not messages:\n            return []\n\n        # Limit messages for performance\n        limited_messages = messages[-30:] if len(messages) > 30 else messages\n        sanitized = []\n\n        for msg in limited_messages:\n            if not isinstance(msg, dict):\n                continue\n\n            clean_msg = msg.copy()\n\n            if isinstance(msg.get(\"content\"), str):\n                content = msg[\"content\"]\n                # Basic cleanup\n                content = re.sub(r\"[ \\t]+\", \" \", content).strip()\n                if len(content) > 40000:  # Reduced limit for better performance\n                    content = content[:40000] + \"...\"\n                clean_msg[\"content\"] = content\n\n            sanitized.append(clean_msg)\n\n        return sanitized\n\n\nclass PerformanceMetrics:\n    \"\"\"Enhanced performance metrics with better memory management\"\"\"\n\n    def __init__(self):\n        self.response_times = []\n        self.error_count = 0\n        self.success_count = 0\n        self.wolfram_calls = 0\n        self._max_history = 50  # Reduced for better memory usage\n\n    def record_response_time(self, duration: float):\n        \"\"\"Record response time with memory management\"\"\"\n        self.response_times.append(duration)\n        if len(self.response_times) > self._max_history:\n            self.response_times.pop(0)\n\n    def record_success(self):\n        self.success_count += 1\n\n    def record_error(self):\n        self.error_count += 1\n\n    def record_wolfram_call(self):\n        self.wolfram_calls += 1\n\n    def get_stats(self) -> Dict[str, Any]:\n        \"\"\"Get optimized statistics\"\"\"\n        avg_time = (\n            sum(self.response_times) / len(self.response_times)\n            if self.response_times\n            else 0\n        )\n        total_requests = self.success_count + self.error_count\n        error_rate = (\n            (self.error_count / total_requests * 100) if total_requests > 0 else 0\n        )\n\n        return {\n            \"avg_response_time\": round(avg_time, 2),\n            \"total_requests\": total_requests,\n            \"success_count\": self.success_count,\n            \"error_count\": self.error_count,\n            \"error_rate_percent\": round(error_rate, 2),\n            \"wolfram_calls\": self.wolfram_calls,\n        }\n\n\nclass GithubCopilotAI:\n    \"\"\"Optimized GitHub Copilot AI client\"\"\"\n\n    def __init__(\n        self, api_key: str, timeout_token: int = 15, timeout_streaming: int = 45\n    ):\n        self.github_token = api_key\n        self.copilot_token = None\n        self.token_expires_at = 0\n        self.timeout_token = timeout_token\n        self.timeout_streaming = timeout_streaming\n\n        # Initialize token cache\n        self.token_cache = TokenCache()\n        self._api_key_hash = hashlib.sha256(api_key.encode()).hexdigest()\n\n        self.base_headers = {\n            \"content-type\": \"application/json\",\n            \"accept\": \"application/json\",\n            \"copilot-integration-id\": \"vscode-chat\",\n            \"editor-version\": \"vscode/1.95.3\",\n            \"editor-plugin-version\": \"copilot-chat/0.27.1\",\n            \"user-agent\": \"GitHubCopilotChat/0.27.1\",\n            \"openai-intent\": \"conversation-panel\",\n            \"x-github-api-version\": \"2025-04-01\",\n        }\n        self.base_url = \"https://api.githubcopilot.com/\"\n\n    def get_copilot_token(self) -> Optional[str]:\n        \"\"\"Optimized token retrieval with caching\"\"\"\n        current_time = time.time()\n\n        # Check memory cache first\n        if self.copilot_token and current_time < self.token_expires_at - 120:\n            return self.copilot_token\n\n        # Check persistent cache\n        cached_data = self.token_cache.get_token(self._api_key_hash)\n        if cached_data:\n            self.copilot_token = cached_data.get(\"token\")\n            self.token_expires_at = cached_data.get(\"expires_at\", 0)\n            return self.copilot_token\n\n        # Fetch new token\n        def _get_token():\n            headers = {\"authorization\": f\"Bearer {self.github_token}\"}\n            headers.update(self.base_headers)\n\n            req = urllib.request.Request(\n                \"https://api.github.com/copilot_internal/v2/token\", headers=headers\n            )\n\n            with urllib.request.urlopen(req, timeout=self.timeout_token) as response:\n                if response.getcode() == 200:\n                    token_data = json.loads(response.read().decode(\"utf-8\"))\n                    self.copilot_token = token_data.get(\"token\")\n                    self.token_expires_at = token_data.get(\"expires_at\", 0)\n                    self.token_cache.save_token(self._api_key_hash, token_data)\n                    return self.copilot_token\n            return None\n\n        try:\n            token = RetryHandler.with_retry(_get_token, max_retries=2)\n            if token:\n                logger.debug(\"Token fetched successfully\")\n            return token\n        except Exception as e:\n            logger.error(f\"Token fetch failed: {e}\")\n            return None\n\n    def list_models(self) -> List[Dict[str, str]]:\n        \"\"\"List available models efficiently\"\"\"\n        working_models = [\n            {\"id\": \"gpt-4o-2024-11-20\", \"name\": \"GPT-4 Omni\"},\n            {\"id\": \"gpt-4\", \"name\": \"GPT-4 2025\"},\n            {\"id\": \"gpt-5-mini\", \"name\": \"GPT-5 Mini\"},\n            {\"id\": \"gpt-4.1-2025-04-14\", \"name\": \"GPT-4.1\"},\n        ]\n\n        current_time = int(time.time())\n        return [\n            {\n                \"id\": model[\"id\"],\n                \"object\": \"model\",\n                \"created\": current_time,\n                \"owned_by\": \"GitHub Copilot\",\n                \"name\": model[\"name\"],\n            }\n            for model in working_models\n        ]\n\n    def chat_completions_create_streaming(self, **kwargs):\n        \"\"\"Optimized streaming chat completion\"\"\"\n        token = self.get_copilot_token()\n        if not token:\n            raise Exception(\"Failed to get Copilot token\")\n\n        headers = self.base_headers.copy()\n        headers[\"Authorization\"] = f\"Bearer {token}\"\n        headers[\"x-request-id\"] = str(uuid.uuid4())\n\n        messages = kwargs.get(\"messages\", [])\n\n        # Determine request type\n        is_agent_call = any(\n            msg.get(\"role\") in [\"assistant\", \"tool\"] for msg in messages\n        )\n        headers[\"X-Initiator\"] = \"agent\" if is_agent_call else \"user\"\n\n        # Check for vision content\n        is_vision_request = any(\n            isinstance(msg.get(\"content\"), list)\n            and any(part.get(\"type\") == \"image_url\" for part in msg[\"content\"])\n            for msg in messages\n        )\n\n        if is_vision_request:\n            headers[\"copilot-vision-request\"] = \"true\"\n\n        kwargs[\"stream\"] = True\n        url = f\"{self.base_url}chat/completions\"\n        request_data = json.dumps(kwargs).encode(\"utf-8\")\n\n        logger.debug(\n            f\"Copilot request - Model: {kwargs.get('model', 'N/A')}, Messages: {len(messages)}\"\n        )\n\n        def _make_request():\n            req = urllib.request.Request(url, data=request_data, headers=headers)\n            return urllib.request.urlopen(req, timeout=self.timeout_streaming)\n\n        try:\n            response = RetryHandler.with_retry(_make_request, max_retries=2)\n            yield from self._process_stream(response, messages)\n\n        except Exception as e:\n            logger.error(f\"Streaming error: {e}\")\n            yield f'data: {json.dumps({\"error\": str(e)})}\\n\\n'\n\n    def _process_stream(self, response, messages):\n        \"\"\"Process streaming response efficiently\"\"\"\n        buffer = \"\"\n        math_detected = any(\n            LaTeXProcessor.detect_math_content(str(msg.get(\"content\", \"\")))\n            for msg in messages[-2:]  # Only check last 2 messages\n        )\n\n        while True:\n            chunk = response.read(8192).decode(\n                \"utf-8\", errors=\"ignore\"\n            )  # Larger chunks\n            if not chunk:\n                break\n\n            buffer += chunk\n            while \"\\n\" in buffer:\n                line, buffer = buffer.split(\"\\n\", 1)\n                line = line.strip()\n\n                if line.startswith(\"data: \"):\n                    data_part = line[6:]\n                    if data_part == \"[DONE]\":\n                        return\n\n                    try:\n                        chunk_data = json.loads(data_part)\n\n                        # Apply LaTeX fixes if needed\n                        if math_detected and \"choices\" in chunk_data:\n                            for choice in chunk_data[\"choices\"]:\n                                if \"delta\" in choice and \"content\" in choice[\"delta\"]:\n                                    content = choice[\"delta\"][\"content\"]\n                                    if content and LaTeXProcessor.detect_math_content(\n                                        content\n                                    ):\n                                        content = LaTeXProcessor.fix_latex_formatting(\n                                            content\n                                        )\n                                        choice[\"delta\"][\"content\"] = content\n\n                        yield f\"data: {json.dumps(chunk_data)}\\n\\n\"\n\n                    except json.JSONDecodeError:\n                        continue\n\n\nclass Pipe:\n    \"\"\"Optimized main Pipe class\"\"\"\n\n    _client: GithubCopilotAI\n    _metrics: PerformanceMetrics\n\n    class Valves(BaseModel):\n        COPILOT_API_KEY: str = Field(\n            default=\"\", description=\"GitHub Copilot API Key (starts with ghu_)\"\n        )\n        DEFAULT_MODEL: str = Field(\n            default=\"gpt-4o\",\n            description=\"Default model to use\",\n            json_schema_extra={\"enum\": [\"gpt-4o\", \"gpt-4\", \"gpt-5-mini\", \"gpt-4.1\"]},\n        )\n        ENABLE_LATEX_ENHANCEMENT: bool = Field(\n            default=True, description=\"Enhance LaTeX formatting\"\n        )\n        ENABLE_WOLFRAM_VERIFICATION: bool = Field(\n            default=True, description=\"Enable Wolfram Alpha verification\"\n        )\n        ENABLE_REQUEST_VALIDATION: bool = Field(\n            default=True, description=\"Validate requests\"\n        )\n        ENABLE_RETRIES: bool = Field(default=True, description=\"Enable retry logic\")\n        MAX_RETRIES: int = Field(\n            default=2,  # Reduced for better performance\n            description=\"Maximum retry attempts\",\n            ge=1,\n            le=3,\n        )\n        TIMEOUT_TOKEN: int = Field(\n            default=15,\n            description=\"Token request timeout (seconds)\",\n            ge=5,\n            le=60,\n        )\n        TIMEOUT_STREAMING: int = Field(\n            default=45,\n            description=\"Streaming timeout (seconds)\",\n            ge=15,\n            le=120,\n        )\n        ENABLE_METRICS: bool = Field(\n            default=True, description=\"Track performance metrics\"\n        )\n        DEBUG_MODE: bool = Field(default=False, description=\"Enable debug logging\")\n\n    def __init__(self):\n        self.id = \"copilot\"\n        self.type = \"manifold\"\n        self.name = \"Copilot Enhanced v2: \"\n\n        # Initialize valves from environment\n        self.valves = self.Valves(\n            COPILOT_API_KEY=os.getenv(\"COPILOT_API_KEY\", \"\"),\n            DEFAULT_MODEL=os.getenv(\"COPILOT_DEFAULT_MODEL\", \"gpt-4o\"),\n            ENABLE_LATEX_ENHANCEMENT=os.getenv(\"COPILOT_ENABLE_LATEX\", \"true\").lower()\n            == \"true\",\n            ENABLE_WOLFRAM_VERIFICATION=os.getenv(\n                \"COPILOT_WOLFRAM_VERIFY\", \"true\"\n            ).lower()\n            == \"true\",\n            ENABLE_REQUEST_VALIDATION=os.getenv(\n                \"COPILOT_ENABLE_VALIDATION\", \"true\"\n            ).lower()\n            == \"true\",\n            ENABLE_RETRIES=os.getenv(\"COPILOT_ENABLE_RETRIES\", \"true\").lower()\n            == \"true\",\n            MAX_RETRIES=int(os.getenv(\"COPILOT_MAX_RETRIES\", \"2\")),\n            TIMEOUT_TOKEN=int(os.getenv(\"COPILOT_TIMEOUT_TOKEN\", \"15\")),\n            TIMEOUT_STREAMING=int(os.getenv(\"COPILOT_TIMEOUT_STREAMING\", \"45\")),\n            ENABLE_METRICS=os.getenv(\"COPILOT_ENABLE_METRICS\", \"true\").lower()\n            == \"true\",\n            DEBUG_MODE=os.getenv(\"COPILOT_DEBUG_MODE\", \"false\").lower() == \"true\",\n        )\n\n        # Initialize metrics\n        self._metrics = PerformanceMetrics()\n\n        # Set logging level\n        if self.valves.DEBUG_MODE:\n            logger.setLevel(logging.DEBUG)\n\n        # Initialize client\n        self._init_client()\n\n    def _init_client(self):\n        \"\"\"Initialize Copilot client with validation\"\"\"\n        if self.valves.COPILOT_API_KEY and self.valves.COPILOT_API_KEY.startswith(\n            \"ghu_\"\n        ):\n            try:\n                self._client = GithubCopilotAI(\n                    api_key=self.valves.COPILOT_API_KEY,\n                    timeout_token=self.valves.TIMEOUT_TOKEN,\n                    timeout_streaming=self.valves.TIMEOUT_STREAMING,\n                )\n                logger.info(\"‚úÖ Copilot client initialized\")\n            except Exception as e:\n                logger.error(f\"‚ùå Client initialization failed: {e}\")\n                self._client = None\n        else:\n            self._client = None\n            if self.valves.COPILOT_API_KEY:\n                logger.warning(\"‚ö†Ô∏è Invalid API key format\")\n\n    def get_all_models(self):\n        \"\"\"Get available models with error handling\"\"\"\n        if not self.valves.COPILOT_API_KEY:\n            return [{\"id\": \"error\", \"name\": \"COPILOT_API_KEY not set\"}]\n\n        if not self.valves.COPILOT_API_KEY.startswith(\"ghu_\"):\n            return [{\"id\": \"error\", \"name\": \"Invalid API key format\"}]\n\n        if not self._client or self._client.github_token != self.valves.COPILOT_API_KEY:\n            self._init_client()\n\n        if not self._client:\n            return [{\"id\": \"error\", \"name\": \"Client initialization failed\"}]\n\n        try:\n            models = self._client.list_models()\n            return [{\"id\": model[\"id\"], \"name\": model[\"name\"]} for model in models]\n        except Exception as e:\n            logger.error(f\"Model listing failed: {e}\")\n            return [{\"id\": \"error\", \"name\": f\"Model fetch failed: {str(e)}\"}]\n\n    def pipes(self) -> List[dict]:\n        \"\"\"Return available models\"\"\"\n        return self.get_all_models()\n\n    def get_metrics(self) -> Dict[str, Any]:\n        \"\"\"Get performance metrics\"\"\"\n        return (\n            self._metrics.get_stats()\n            if self.valves.ENABLE_METRICS\n            else {\"metrics_disabled\": True}\n        )\n\n    def health_check(self) -> bool:\n        \"\"\"Health check with minimal overhead\"\"\"\n        try:\n            if not self._client:\n                return False\n\n            token = self._client.get_copilot_token()\n            return token is not None\n        except Exception:\n            return False\n\n    async def pipe(\n        self,\n        body: dict,\n        __event_emitter__=None,\n        __tools__=None,\n        __user__=None,\n        __model__=None,\n    ) -> Iterator[str]:\n        \"\"\"\n        Optimized main pipe method with cleaner event handling.\n\n        Only emits critical error notifications, no status updates during chat.\n        \"\"\"\n        if not self._client:\n            error_msg = (\n                \"‚ö†Ô∏è API key not configured. Please set your GitHub Copilot API key.\"\n            )\n            logger.error(error_msg)\n            yield f'data: {json.dumps({\"error\": error_msg})}\\n\\n'\n            return\n\n        start_time = time.time()\n\n        try:\n            logger.debug(\n                f\"Processing request for user: {__user__.get('name') if __user__ else 'Unknown'}\"\n            )\n\n            # 1. Validate and sanitize input\n            if self.valves.ENABLE_REQUEST_VALIDATION:\n                body = RequestValidator.validate_and_sanitize(body)\n\n            # 2. Extract model and messages\n            model_id = body.get(\"model\", self.valves.DEFAULT_MODEL)\n            if \".\" in model_id:\n                model_id = model_id.split(\".\", 1)[1]\n\n            if \"messages\" not in body:\n                yield 'data: {\"error\": \"No messages provided\"}\\n\\n'\n                return\n\n            # 3. Get user message and detect math\n            user_message = \"\"\n            if body[\"messages\"]:\n                last_msg = body[\"messages\"][-1]\n                if isinstance(last_msg.get(\"content\"), str):\n                    user_message = last_msg[\"content\"]\n\n            is_math = MathDetector.is_math_query(user_message)\n            wolfram_tool = None\n\n            # 4. Find Wolfram tool if math detected\n            if is_math and self.valves.ENABLE_WOLFRAM_VERIFICATION and __tools__:\n                for tool_id, tool in __tools__.items():\n                    if \"wolfram\" in tool_id.lower():\n                        wolfram_tool = tool\n                        logger.debug(f\"Wolfram tool found: {tool_id}\")\n                        break\n\n            # 5. Prepare request kwargs\n            kwargs = body.copy()\n            kwargs[\"model\"] = model_id\n            kwargs[\"stream\"] = True\n\n            # 6. Enhance for LaTeX if needed\n            if self.valves.ENABLE_LATEX_ENHANCEMENT:\n                original_messages = kwargs[\"messages\"]\n                enhanced_messages = LaTeXProcessor.enhance_math_prompt(\n                    original_messages, has_wolfram=wolfram_tool is not None\n                )\n                if enhanced_messages != original_messages:\n                    kwargs[\"messages\"] = enhanced_messages\n\n            # 7. Execute streaming request\n            def _stream_request():\n                return self._client.chat_completions_create_streaming(**kwargs)\n\n            if self.valves.ENABLE_RETRIES:\n                stream_generator = RetryHandler.with_retry(\n                    _stream_request, max_retries=self.valves.MAX_RETRIES\n                )\n            else:\n                stream_generator = _stream_request()\n\n            # 8. Stream response and accumulate for Wolfram\n            full_response = \"\"\n            for chunk in stream_generator:\n                yield chunk\n\n                # Accumulate response for Wolfram verification\n                if wolfram_tool and is_math:\n                    try:\n                        chunk_json = chunk[6:] if chunk.startswith(\"data: \") else chunk\n                        chunk_data = json.loads(chunk_json)\n                        if \"choices\" in chunk_data:\n                            for choice in chunk_data[\"choices\"]:\n                                if \"delta\" in choice and \"content\" in choice[\"delta\"]:\n                                    full_response += choice[\"delta\"][\"content\"]\n                    except (json.JSONDecodeError, KeyError):\n                        pass\n\n            # 9. Wolfram verification (if applicable)\n            if wolfram_tool and is_math and full_response:\n                if self.valves.ENABLE_METRICS:\n                    self._metrics.record_wolfram_call()\n\n                logger.debug(\"Initiating Wolfram verification\")\n\n                expression = MathDetector.extract_expression(user_message)\n                math_type = MathDetector.get_math_type(user_message)\n\n                if expression:\n                    try:\n                        # Call appropriate Wolfram method\n                        if hasattr(wolfram_tool, \"verify_math\"):\n                            wolfram_result = await wolfram_tool.verify_math(\n                                expression=expression,\n                                operation=math_type or \"auto\",\n                                __event_emitter__=None,  # No events during verification\n                            )\n                        elif hasattr(wolfram_tool, \"query_wolfram\"):\n                            wolfram_result = await wolfram_tool.query_wolfram(\n                                query=user_message,\n                                __event_emitter__=None,\n                            )\n                        else:\n                            wolfram_result = None\n\n                        # Format and yield verification result\n                        if wolfram_result:\n                            try:\n                                result_data = (\n                                    WolframResultFormatter.parse_wolfram_response(\n                                        wolfram_result\n                                    )\n                                )\n                                if result_data.get(\"success\"):\n                                    verification_text = WolframResultFormatter.format_verification_block(\n                                        result_data\n                                    )\n\n                                    verification_chunk = {\n                                        \"id\": str(uuid.uuid4()),\n                                        \"object\": \"chat.completion.chunk\",\n                                        \"created\": int(time.time()),\n                                        \"model\": model_id,\n                                        \"choices\": [\n                                            {\n                                                \"index\": 0,\n                                                \"delta\": {\"content\": verification_text},\n                                                \"finish_reason\": None,\n                                            }\n                                        ],\n                                    }\n                                    yield f\"data: {json.dumps(verification_chunk)}\\n\\n\"\n                            except json.JSONDecodeError:\n                                pass\n\n                    except Exception as e:\n                        logger.error(f\"Wolfram verification failed: {e}\")\n\n            # 10. Record success metrics\n            if self.valves.ENABLE_METRICS:\n                duration = time.time() - start_time\n                self._metrics.record_response_time(duration)\n                self._metrics.record_success()\n\n            logger.debug(f\"Request completed in {time.time() - start_time:.2f}s\")\n\n        except Exception as e:\n            error_msg = str(e)\n            logger.error(f\"Pipe error: {error_msg}\", exc_info=self.valves.DEBUG_MODE)\n\n            if self.valves.ENABLE_METRICS:\n                self._metrics.record_error()\n\n            # Generate user-friendly error message\n            if \"token\" in error_msg.lower() or \"401\" in error_msg:\n                friendly_msg = \"üîë Authentication error. Please verify your API key.\"\n            elif \"timeout\" in error_msg.lower():\n                friendly_msg = \"‚åõ Request timed out. Please try again.\"\n            elif \"429\" in error_msg or \"rate limit\" in error_msg.lower():\n                friendly_msg = \"‚è≥ Rate limit exceeded. Please wait and try again.\"\n            elif \"connection\" in error_msg.lower():\n                friendly_msg = \"üåê Connection error. Check your internet connection.\"\n            else:\n                friendly_msg = f\"‚ùå Error: {error_msg if self.valves.DEBUG_MODE else 'Check logs for details'}\"\n\n            yield f'data: {json.dumps({\"error\": friendly_msg})}\\n\\n'\n\n            # Send critical error notification (appears in corner, not during chat)\n            if __event_emitter__ and (\n                \"401\" in error_msg or \"token\" in error_msg.lower()\n            ):\n                await __event_emitter__(\n                    {\n                        \"type\": \"notification\",\n                        \"data\": {\n                            \"type\": \"error\",\n                            \"content\": \"GitHub Copilot API key is invalid or expired. Please update it in settings.\",\n                        },\n                    }\n                )\n","meta":{"description":"Enhanced GitHub ","manifest":{"title":"GitHub Copilot Enhanced v2.0 - Optimized","author":"AI Assistant with improvements","version":"2.0.0","required_open_webui_version":"0.4.0","license":"MIT","description":"Optimized GitHub Copilot integration with improved performance, cleaner event handling, and better error management","requirements":"pydantic"}},"is_active":true,"is_global":false,"updated_at":1759811832,"created_at":1759811799}]